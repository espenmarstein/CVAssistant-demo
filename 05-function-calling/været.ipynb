{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Få tak i værdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to execute 3 tool calls in parallel:\n",
      "Calling tool: \"get_weather\" with parameters: {\"location\": \"Oslo\"}\n",
      "Sending tool return value back to GPT\n",
      "\n",
      "Calling tool: \"get_weather\" with parameters: {\"location\": \"Trondheim\"}\n",
      "Sending tool return value back to GPT\n",
      "\n",
      "Calling tool: \"get_weather\" with parameters: {\"location\": \"Bergen\"}\n",
      "Sending tool return value back to GPT\n",
      "\n",
      "\n",
      "Response:\n",
      "Været i Oslo er lys, lyn og varme med en temperatur på 5 grader. I Trondheim er det sol og snø med en temperatur på 10 grader. Bergen har også sol og snø med en temperatur på 10 grader. \n",
      "\n",
      "Temperaturforskjellen mellom Oslo og Trondheim er 5 grader.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "messages = [\n",
    "  {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a weather reporter.\",\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    #\"content\": \"Hvordan er været i Oslo?\",\n",
    "    \"content\": \"Hvordan er været i Oslo? Og hva med Trondheim? Og hva er temperaturforskjellen mellom de to byene? Hva med Bergen?\",\n",
    "  }\n",
    "]\n",
    "\n",
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_weather\",\n",
    "      \"description\": \"Get the weather for a given location.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The location to get the weather for.\",\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "def get_weather(location):\n",
    "  #import requests\n",
    "  #response = requests.get(f\"https://wttr.in/{location}?format=j1\").json()\n",
    "  #return json.dumps(response[\"current_condition\"][0])\n",
    "  return [\"Sol og snø, 10 grader\", \"Lys, lyn og varme, 5 grader\", \"Regn og trist, -1 grad\"][len(location) % 3]\n",
    "\n",
    "tools_functions = {\n",
    "  \"get_weather\": lambda args: get_weather(args[\"location\"])\n",
    "}\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "  if i > 10:\n",
    "    print(\"Too many tool calls.\")\n",
    "    break\n",
    "  i += 1\n",
    "\n",
    "  if completion.choices[0].finish_reason == \"stop\":\n",
    "    print()\n",
    "    print(\"Response:\")\n",
    "    print(completion.choices[0].message.content)\n",
    "    break\n",
    "\n",
    "  if completion.choices[0].finish_reason == \"tool_calls\":\n",
    "    tool_calls = []\n",
    "    tool_results = []\n",
    "    tool_calls_count = len(completion.choices[0].message.tool_calls)\n",
    "    if tool_calls_count > 1:\n",
    "      print(f\"Going to execute {tool_calls_count} tool calls in parallel:\")\n",
    "    for call in completion.choices[0].message.tool_calls:\n",
    "      tool_id = call.id\n",
    "      tool_name = call.function.name\n",
    "      tool_args = call.function.arguments\n",
    "      print(f\"Calling tool: \\\"{call.function.name}\\\" with parameters: \" + str(tool_args).replace(\"\\n\", \" \").replace(\"   \", \" \"))\n",
    "      value = tools_functions[tool_name](json.loads(tool_args))\n",
    "      tool_calls.append({\n",
    "        \"id\": tool_id,\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "          \"name\": tool_name,\n",
    "          \"arguments\": tool_args,\n",
    "        }\n",
    "      })\n",
    "      tool_results.append({\n",
    "          \"role\": \"tool\",\n",
    "          \"content\": str(value),\n",
    "          \"tool_call_id\": tool_id,\n",
    "      })\n",
    "      print(\"Sending tool return value back to GPT\")\n",
    "      print()\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"tool_calls\": tool_calls,\n",
    "    })\n",
    "\n",
    "    messages += tool_results\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        temperature=0,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
